{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ja62mICza1OZ",
    "outputId": "ce3f8030-4a1c-4a4b-c57c-f1f4a48f390a"
   },
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "#!pip uninstall spacy\n",
    "#!pip install spacy==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CibQZ-zba1Oc"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "import gzip\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "try:\n",
    "    from Bio import Entrez\n",
    "except ModuleNotFoundError:\n",
    "    !pip install Bio\n",
    "    from Bio import Entrez\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "\n",
    "response = urllib.request.urlopen('ftp://mirbase.org/pub/mirbase/CURRENT/miRNA.xls.gz')\n",
    "compressed_file = io.BytesIO(response.read())\n",
    "decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n",
    "\n",
    "with open(Path(os.getcwd(), 'miRNA.xlsx'), 'wb') as outfile:\n",
    "    outfile.write(decompressed_file.read())\n",
    "\n",
    "mir_database = pd.read_excel('miRNA.xlsx')\n",
    "\n",
    "mir_database_1 = mir_database.loc[:, ['Accession', 'ID']]\n",
    "mir_database_2 = mir_database.loc[:, ['Mature1_Acc', 'Mature1_ID']].rename(columns = {'Mature1_Acc':'Accession', 'Mature1_ID':'ID'})\n",
    "mir_database_3 = mir_database.loc[:, ['Mature2_Acc', 'Mature2_ID']].rename(columns = {'Mature2_Acc':'Accession', 'Mature2_ID':'ID'})\n",
    "\n",
    "final_database = pd.concat([mir_database_1, mir_database_2, mir_database_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vs5mReFqpmdh",
    "outputId": "09d50aca-caf8-49b5-a5ba-273d686da1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.5\n"
     ]
    }
   ],
   "source": [
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QsyN70Ria1Oe"
   },
   "outputs": [],
   "source": [
    "def fetch_abstract(pmid):\n",
    "    handle = Entrez.efetch(db='pubmed', id = pmid, retmode='xml')\n",
    "    article = Entrez.read(handle)['PubmedArticle'][0]['MedlineCitation']['Article']\n",
    "    if 'Abstract' in article:\n",
    "            return article['Abstract']['AbstractText']\n",
    "        \n",
    "def concat_article(x):\n",
    "    final_article = str()\n",
    "    for i in range(len(x)):\n",
    "        final_article = final_article + str(x[i]) + ' '\n",
    "    return final_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dtyYyq0_a1Oe"
   },
   "outputs": [],
   "source": [
    "def get_literature(user_mir):\n",
    "    \n",
    "    filtered_database = final_database[final_database['Accession']  == user_mir]['ID']\n",
    "    filtered_database = final_database[final_database['Accession']  == user_mir]['ID']\n",
    "\n",
    "    if filtered_database.size == 1:\n",
    "        mir = filtered_database.iloc[0]\n",
    "        print('The accession number ' + user_mir + ' corresponds to miR ' + mir)\n",
    "    else:\n",
    "        print('miR accession is incorrect. Try again (caps sensitive)')\n",
    "\n",
    "    Entrez.email = 'anonymous@gmail.com'\n",
    "    esearch_query = Entrez.esearch(db=\"pubmed\", term=\"mir-100\", retmode=\"xml\")\n",
    "    esearch_result = Entrez.read(esearch_query)\n",
    "    pmid_list = esearch_result['IdList']\n",
    "    print(\"pmid's obtained: \" + str(len(pmid_list)))\n",
    "    \n",
    "    abs_list = []\n",
    "\n",
    "    for i in pmid_list:\n",
    "        abs = fetch_abstract(i)\n",
    "        abs_list.append(abs)\n",
    "        \n",
    "    abs_list = [concat_article(i) for i in abs_list if i is not None]\n",
    "    \n",
    "    return(abs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_jDd_01Xa1Og"
   },
   "outputs": [],
   "source": [
    "training_mir = ['MI0000692', 'MI0000159', 'MI0000172', 'MI0000406', 'MI0000111', 'MI0000684', 'MI0000256', 'MI0000170', 'MI0000268', 'MI0002470']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eLZbnXLa1Oh",
    "outputId": "29b46ff1-756a-4b00-dea9-bca8f568fc48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accession number MI0000692 corresponds to miR mmu-mir-100\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000159 corresponds to miR mmu-mir-133a-1\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000172 corresponds to miR mmu-mir-150\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000406 corresponds to miR mmu-mir-106a\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000111 corresponds to miR hsa-mir-105-1\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000684 corresponds to miR mmu-mir-107\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000256 corresponds to miR mmu-mir-122\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000170 corresponds to miR mmu-mir-146a\n",
      "pmid's obtained: 20\n",
      "The accession number MI0000268 corresponds to miR hsa-mir-34a\n",
      "pmid's obtained: 20\n",
      "The accession number MI0002470 corresponds to miR hsa-mir-486-1\n",
      "pmid's obtained: 20\n"
     ]
    }
   ],
   "source": [
    "all_abstracts = []\n",
    "\n",
    "for i in training_mir:\n",
    "    abstracts = get_literature(i)\n",
    "    all_abstracts = all_abstracts + abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hDBi8V51a1Oh"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "for mir_abs in all_abstracts:\n",
    "    abstr_sentences = sent_tokenize(mir_abs)\n",
    "    all_sentences = all_sentences + abstr_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = all_sentences[0:int(.8 * len(all_sentences))]\n",
    "testing_sentences = all_sentences[int(.8 * len(all_sentences)):len(all_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YTAu95Mza1Ox"
   },
   "outputs": [],
   "source": [
    "def make_training_data(string):\n",
    "    if len([i for i in re.finditer('mir-\\d+[^\\s|.|,|!|?| |:|;]*', string.lower())]) != 0:\n",
    "        ent_list = []\n",
    "        for i in re.finditer('mir-\\d+[^\\s|.|,|!|?| |:|;]*', string.lower()):\n",
    "            ent_code = (i.start(), i.end(), 'miR')\n",
    "            ent_list.append(ent_code)\n",
    "            \n",
    "    else:\n",
    "        ent_list = []      \n",
    "    return((string, {'entities' : ent_list}))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mu7AR86Ka1O0"
   },
   "outputs": [],
   "source": [
    "training_data = [make_training_data(i) for i in training_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkWlystea1O0",
    "outputId": "3ad41c34-2678-4eb7-b4be-b2e23833a394"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Moreover, CCND1 was shown to be a novel target gene of miR-194 in GC.',\n",
       "  {'entities': [(55, 62, 'miR')]}),\n",
       " ('PCa cells were transfected with NC-mimics or miR-100-5p mimics, inhibitor by using liposome transfection.',\n",
       "  {'entities': [(45, 55, 'miR')]}),\n",
       " ('Expression of eca-miR-100 and eca-miR-1 was not different between groups.',\n",
       "  {'entities': [(18, 25, 'miR'), (34, 39, 'miR')]})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtQNfOkxa1O2",
    "outputId": "2796a195-38a4-4324-b0b9-ee87341f739a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-lookups-data in ./lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.7/site-packages (from spacy-lookups-data) (40.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-lookups-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kGO24gY0a1O2"
   },
   "outputs": [],
   "source": [
    "def train_spacy(data,iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "       \n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.2,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MLex50Pa1O2",
    "outputId": "325308b3-0398-4593-f7d1-349de13bc29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 1162.650378093236}\n",
      "Starting iteration 1\n",
      "{'ner': 309.35683442019365}\n",
      "Starting iteration 2\n",
      "{'ner': 102.06620370620945}\n",
      "Starting iteration 3\n",
      "{'ner': 158.36978899452725}\n",
      "Starting iteration 4\n",
      "{'ner': 37.76365348176094}\n",
      "Starting iteration 5\n",
      "{'ner': 294.65522586023627}\n",
      "Starting iteration 6\n",
      "{'ner': 47.67403523577628}\n",
      "Starting iteration 7\n",
      "{'ner': 29.274067601147642}\n",
      "Starting iteration 8\n",
      "{'ner': 55.70227766505165}\n",
      "Starting iteration 9\n",
      "{'ner': 17.553434002926913}\n"
     ]
    }
   ],
   "source": [
    "miRnlp = train_spacy(training_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIMgjHNGa1O4",
    "outputId": "2f1a7513-5fe6-4fce-d302-7b7fea2f8831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because of the high number of miRNAs, we more closely evaluated the expression of six of them (miR-100-5p, miR-29a-3p, miR-130a-3p, miR-10a-5p, miR-10b-5p, miR-203a), and determined that their levels were dramatically changed by at least 50-fold at different time points of the experiment (p < 0.01).\n",
      "Entities [('miR-100-5p', 'miR'), ('miR-29a-3p', 'miR'), ('miR-130a-3p', 'miR'), ('miR-10a-5p', 'miR'), ('miR-10b-5p', 'miR'), ('miR-203a)', 'miR')]\n",
      "\n",
      "Because of the high number of miRNAs, we more closely evaluated the expression of six of them (miR-100-5p, miR-29a-3p, miR-130a-3p, miR-10a-5p, miR-10b-5p, miR-203a), and determined that their levels were dramatically changed by at least 50-fold at different time points of the experiment (p < 0.01).\n",
      "Entities [('miR-100-5p', 'miR'), ('miR-29a-3p', 'miR'), ('miR-130a-3p', 'miR'), ('miR-10a-5p', 'miR'), ('miR-10b-5p', 'miR'), ('miR-203a)', 'miR')]\n",
      "\n",
      "<i>p</i> < 0.05), whereas the expression of 16 miRNAs was significantly decreased (> 1.5-fold, adj.\n",
      "Entities []\n",
      "\n",
      "Quantitative reverse transcription polymerase chain reaction and western blot were used to detect the expression of the adhesion factors, apoptosis-related proteins and Notch pathway-related protein.\n",
      "Entities []\n",
      "\n",
      "Here, we aimed to investigate epicardial signalling via EV release in response to cardiac injury and as a means to optimise cardiac repair and regeneration.\n",
      "Entities []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in testing_sentences[0:5]:\n",
    "    print(i)\n",
    "    doc = miRnlp(i)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_virtualenv",
   "language": "python",
   "name": "my_virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
